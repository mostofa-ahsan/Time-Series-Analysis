{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf  #TF 1.1.0rc1\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import matplotlib.pyplot as plt\n",
    "from tsc_model import Model,sample_batch,load_data,check_test\n",
    "\n",
    "#Set these directories\n",
    "direc = '/home/mkahsan/ml_projects/LSTM/UCR_TS_Archive_2015'\n",
    "summaries_dir = '/home/mkahsan/ml_projects/LSTM_TSC/log_tb'\n",
    "\n",
    "\"\"\"Load the data\"\"\"\n",
    "ratio = np.array([0.8,0.9]) #Ratios where to split the training and validation set\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = load_data(direc,ratio,dataset='ChlorineConcentration')\n",
    "N,sl = X_train.shape\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "\"\"\"Hyperparamaters\"\"\"\n",
    "batch_size = 30\n",
    "max_iterations = 3000\n",
    "dropout = 0.8\n",
    "config = {    'num_layers' :    3,               #number of layers of stacked RNN's\n",
    "              'hidden_size' :   120,             #memory cells in a layer\n",
    "              'max_grad_norm' : 5,             #maximum gradient norm during training\n",
    "              'batch_size' :    batch_size,\n",
    "              'learning_rate' : .005,\n",
    "              'sl':             sl,\n",
    "              'num_classes':    num_classes}\n",
    "\n",
    "\n",
    "\n",
    "epochs = np.floor(batch_size*max_iterations / N)\n",
    "print('Train %.0f samples in approximately %d epochs' %(N,epochs))\n",
    "\n",
    "#Instantiate a model\n",
    "model = Model(config)\n",
    "\n",
    "\"\"\"Session time\"\"\"\n",
    "sess = tf.Session() #Depending on your use, do not forget to close the session\n",
    "writer = tf.summary.FileWriter(summaries_dir, sess.graph)  #writer for Tensorboard\n",
    "sess.run(model.init_op)\n",
    "\n",
    "cost_train_ma = -np.log(1/float(num_classes)+1e-9)  #Moving average training cost\n",
    "acc_train_ma = 0.0\n",
    "try:\n",
    "  for i in range(max_iterations):\n",
    "    X_batch, y_batch = sample_batch(X_train,y_train,batch_size)\n",
    "\n",
    "    #Next line does the actual training\n",
    "    cost_train, acc_train,_ = sess.run([model.cost,model.accuracy, model.train_op],feed_dict = {model.input: X_batch,model.labels: y_batch,model.keep_prob:dropout})\n",
    "    cost_train_ma = cost_train_ma*0.99 + cost_train*0.01\n",
    "    acc_train_ma = acc_train_ma*0.99 + acc_train*0.01\n",
    "    if i%100 == 1:\n",
    "    #Evaluate validation performance\n",
    "      X_batch, y_batch = sample_batch(X_val,y_val,batch_size)\n",
    "      cost_val, summ,acc_val = sess.run([model.cost,model.merged,model.accuracy],feed_dict = {model.input: X_batch, model.labels: y_batch, model.keep_prob:1.0})\n",
    "      print('At %5.0f/%5.0f: COST %5.3f/%5.3f(%5.3f) -- Acc %5.3f/%5.3f(%5.3f)' %(i,max_iterations,cost_train,cost_val,cost_train_ma,acc_train,acc_val,acc_train_ma))\n",
    "      #Write information to TensorBoard\n",
    "      writer.add_summary(summ, i)\n",
    "      writer.flush()\n",
    "except KeyboardInterrupt:\n",
    "  pass\n",
    "  \n",
    "epoch = float(i)*batch_size/N\n",
    "print('Trained %.1f epochs, accuracy is %5.3f and cost is %5.3f'%(epoch,acc_val,cost_val))\n",
    "\n",
    "#now run in your terminal:\n",
    "# $ tensorboard --logdir = <summaries_dir>\n",
    "# Replace <summaries_dir> with your own dir"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
